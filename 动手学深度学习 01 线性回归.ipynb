{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 线性回归\n",
    "这个笔记添加了一些注释和个人对代码的理解"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=1000\n",
    "a=torch.ones(n) # 生成1000维大小为一的标量\n",
    "b=torch.ones(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# timer class\n",
    "class Timer (object):\n",
    "    def __init__(self): #python的构造函数\n",
    "        self.times=[]   #self.XXX 定义python类的变量\n",
    "        self.start()\n",
    "    \n",
    "    def start(self):\n",
    "        self.start_time = time.time()\n",
    "        \n",
    "    def stop(self):\n",
    "        self.times.append(time.time() - self.start_time) # append 类似于c++数组的push_back 在尾部添加元素\n",
    "        return self.times[-1]                           # [-1] 取倒数第一位\n",
    "    \n",
    "    def avg(self):\n",
    "        return sum(self.times)/len(self.times)          # 计算平均运行时长\n",
    "    \n",
    "    def sum(self):\n",
    "        return sum(self.times)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1, 用for循环作标量加法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04383969306945801\n"
     ]
    }
   ],
   "source": [
    "timer = Timer()\n",
    "c=torch.zeros(n) # 生成1000维大小为0的标量\n",
    "for i in range(n) :\n",
    "    c[i] = a[i]+b[i]\n",
    "print(timer.stop())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2,用pytorch运行标量加法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.00000 sec'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timer.start()\n",
    "d=a+b\n",
    "'%.5f sec'% timer.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "显然pytorch更快"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 下面用tenserflow 运行同样代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_a = tf.ones(n)\n",
    "tf_b = tf.ones(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.00000 sec'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timer.start()\n",
    "tf_d=a+b\n",
    "'%.5f sec'% timer.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "显然pytorch与tenserflow 不分彼此"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 线性回归模型从零开始"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4.0\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import torch\n",
    "from IPython import display  \n",
    "from matplotlib import pyplot as plt #散点图\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_inputs = 2\n",
    "num_examples = 1000\n",
    "\n",
    "true_w = [2, -3.4]\n",
    "true_b = 4.2\n",
    "\n",
    "features = torch.randn(num_examples, num_inputs,dtype=torch.float32)  #随机生成1000*2的数据\n",
    "labels = true_w[0] * features[:, 0] + true_w[1] * features[:, 1] + true_b\n",
    "labels += torch.tensor(np.random.normal(0, 0.01, size=labels.size()),dtype=torch.float32) # 为结果加入随机偏差 模拟真实数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "图像展示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(features[:, 1].numpy(), labels.numpy(), 1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "读取数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_iter(batch_size, features, labels):\n",
    "    num_examples = len(features)\n",
    "    indices = list(range(num_examples)) #生成一个与数据长度相等的序列【0--num_examples】 并转换成列表\n",
    "    random.shuffle(indices)  # 将序列随机重新排序\n",
    "    for i in range(0, num_examples, batch_size): #for循环 i从0到num_examples 步长是 batch_size\n",
    "        j = torch.LongTensor(indices[i: min(i + batch_size, num_examples)]) # 每次循环取batch_size个序列\n",
    "        yield  features.index_select(0, j), labels.index_select(0, j)   \n",
    "        # index_select()参数0指行，1指列  \n",
    "        # 输出j中序列代表的行，从而实现随机读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.5536,  0.1213],\n",
      "        [ 2.2359, -2.0172],\n",
      "        [ 1.1767, -1.3213],\n",
      "        [-0.2732,  0.1535],\n",
      "        [-2.1978,  0.1922],\n",
      "        [-0.3637,  1.0271],\n",
      "        [-0.9810,  1.5348],\n",
      "        [ 1.1957,  0.7572],\n",
      "        [-0.3323,  0.9395],\n",
      "        [-1.2617, -0.8727]]) \n",
      " tensor([ 4.8934, 15.5179, 11.0384,  3.1352, -0.8537, -0.0161, -2.9755,  4.0205,\n",
      "         0.3548,  4.6584])\n"
     ]
    }
   ],
   "source": [
    "batch_size = 10\n",
    "\n",
    "for X, y in data_iter(batch_size, features, labels):\n",
    "    print(X, '\\n', y)\n",
    "    break           # 跳出循环 只输出10个数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "初始化模型参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.], requires_grad=True)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = torch.tensor(np.random.normal(0, 0.01, (num_inputs, 1)), dtype=torch.float32) #利用正态分布随机成成2*1的参数\n",
    "b = torch.zeros(1, dtype=torch.float32)\n",
    "\n",
    "w.requires_grad_(requires_grad=True)   #通过该参数来设置是否对该变量求导 （梯度下降法）\n",
    "b.requires_grad_(requires_grad=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linreg(X, w, b):\n",
    "    return torch.mm(X, w) + b  #torch.mm() 矩阵相乘  n行2列的矩阵X 乘 2行1列矩阵w =》n行一列矩阵   即X1*w1+X2*w2+b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义损失函数 使用均方误差"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def squared_loss(y_hat, y): \n",
    "    return (y_hat - y.view(y_hat.size())) ** 2 / 2  # y.view(y_hat.size()) y只有一行，将y转换成与y_hat相同行数的列向量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义小批量随机下降  优化函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sgd(params, lr, batch_size): \n",
    "    for param in params:\n",
    "        param.data -= lr * param.grad / batch_size # .data 返回和 x 的相同数据 tensor, 但不会加入到x的计算历史里"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss 0.024333\n",
      "epoch 2, loss 0.000081\n",
      "epoch 3, loss 0.000047\n",
      "epoch 4, loss 0.000048\n",
      "epoch 5, loss 0.000047\n"
     ]
    }
   ],
   "source": [
    "# 超参数 超参数指模型无法自动调参需要手动设置的参数\n",
    "lr = 0.03\n",
    "num_epochs = 5\n",
    "\n",
    "net = linreg\n",
    "loss = squared_loss\n",
    "\n",
    "# training\n",
    "for epoch in range(num_epochs):  # training repeats num_epochs times\n",
    "    # in each epoch, all the samples in dataset will be used once\n",
    "    \n",
    "    # X is the feature and y is the label of a batch sample\n",
    "    for X, y in data_iter(batch_size, features, labels):\n",
    "        l = loss(net(X, w, b), y).sum()  \n",
    "        # calculate the gradient of batch sample loss \n",
    "        l.backward()  #反向传播 计算梯度\n",
    "        # using small batch random gradient descent to iter model parameters\n",
    "        sgd([w, b], lr, batch_size)  \n",
    "        # reset parameter gradient\n",
    "        #  grad在反向传播过程中是累加的(accumulated)，这意味着每一次运行反向传播，梯度都会累加之前的梯度，所以一般在反向传播之前需把梯度清零。\n",
    "        w.grad.data.zero_()\n",
    "        b.grad.data.zero_()\n",
    "    train_l = loss(net(features, w, b), labels)\n",
    "    print('epoch %d, loss %f' % (epoch + 1, train_l.mean().item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 2.0003],\n",
       "         [-3.3989]], requires_grad=True),\n",
       " [2, -3.4],\n",
       " tensor([4.2000], requires_grad=True),\n",
       " 4.2)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w, true_w, b, true_b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 线性回归pytorch实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "torch.manual_seed(1)\n",
    "\n",
    "print(torch.__version__)\n",
    "torch.set_default_tensor_type('torch.FloatTensor')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据集 和上面一样"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_inputs = 2\n",
    "num_examples = 1000\n",
    "\n",
    "true_w = [2, -3.4]\n",
    "true_b = 4.2\n",
    "\n",
    "features = torch.tensor(np.random.normal(0, 1, (num_examples, num_inputs)), dtype=torch.float)\n",
    "labels = true_w[0] * features[:, 0] + true_w[1] * features[:, 1] + true_b\n",
    "labels += torch.tensor(np.random.normal(0, 0.01, size=labels.size()), dtype=torch.float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "读取数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  PyTorch提供了data包来读取数据。由于data常用作变量名，我们将导入的data模块用Data代替。在每一次迭代中，我们将随机读取包含10个数据样本的小批量。\n",
    "import torch.utils.data as Data\n",
    "\n",
    "batch_size = 10\n",
    "\n",
    "# combine featues and labels of dataset\n",
    "dataset = Data.TensorDataset(features, labels)\n",
    "\n",
    "# put dataset into DataLoader\n",
    "data_iter = Data.DataLoader(\n",
    "    dataset=dataset,            # torch TensorDataset format\n",
    "    batch_size=batch_size,      # mini batch size\n",
    "    shuffle=True,               # whether shuffle the data or not\n",
    "    num_workers=2,              # read data in multithreading\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.4284,  0.3224],\n",
      "        [-0.6120,  0.5307],\n",
      "        [ 0.1511, -1.9899],\n",
      "        [-0.0486,  0.4757],\n",
      "        [ 1.2438, -1.3689],\n",
      "        [ 0.4543,  0.7067],\n",
      "        [ 1.6300,  1.7061],\n",
      "        [ 0.9088, -0.7688],\n",
      "        [ 0.7028, -0.7059],\n",
      "        [-0.5255, -0.6703]]) \n",
      " tensor([ 5.9552,  1.1702, 11.2862,  2.5107, 11.3590,  2.6873,  1.6673,  8.6199,\n",
      "         8.0162,  5.4509])\n"
     ]
    }
   ],
   "source": [
    "for X, y in data_iter:\n",
    "    print(X, '\\n', y)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearNet(\n",
      "  (linear): Linear(in_features=2, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class LinearNet(nn.Module): # 继承nn.modul\n",
    "    def __init__(self, n_feature):\n",
    "        super(LinearNet, self).__init__()      # call father function to init  官方文档也是这样写的，具体含义不晓得\n",
    "        self.linear = nn.Linear(n_feature, 1)  # function prototype: `torch.nn.Linear(in_features, out_features, bias=True)`\n",
    "                                               # 线性回归成为当前modul的子模块，成为树结构的一个叶子。\n",
    "    def forward(self, x):\n",
    "        y = self.linear(x)\n",
    "        return y\n",
    "    \n",
    "net = LinearNet(num_inputs)\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "构建神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (linear): Linear(in_features=2, out_features=1, bias=True)\n",
      ")\n",
      "Linear(in_features=2, out_features=1, bias=True)\n"
     ]
    }
   ],
   "source": [
    "# Sequential是一个有序的容器，网络层将按照在传入Sequential的顺序依次被添加到计算图中。\n",
    "# 一种顺序容器。传入Sequential构造器中的模块会被按照他们传入的顺序依次添加到Sequential之上。\n",
    "# 相应的，一个由模块组成的顺序词典也可以被传入到Sequential的构造器中。\n",
    "# 写法一\n",
    "net = nn.Sequential(\n",
    "    nn.Linear(num_inputs, 1)\n",
    "    # 此处还可以传入其他层\n",
    "    )\n",
    "\n",
    "# 写法二\n",
    "net = nn.Sequential()\n",
    "net.add_module('linear', nn.Linear(num_inputs, 1))\n",
    "# net.add_module ......\n",
    "\n",
    "# 写法三\n",
    "from collections import OrderedDict\n",
    "net = nn.Sequential(OrderedDict([\n",
    "          ('linear', nn.Linear(num_inputs, 1))\n",
    "          # ......\n",
    "        ]))\n",
    "\n",
    "print(net)\n",
    "print(net[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "初始化参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([0.], requires_grad=True)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.nn import init\n",
    "\n",
    "init.normal_(net[0].weight, mean=0.0, std=0.01)  #正态初始化\n",
    "init.constant_(net[0].bias, val=0.0)  # or you can use `net[0].bias.data.fill_(0)` to modify it directly\n",
    "                                      # 常量初始化 ，依然不明白.data\n",
    "# net[0] 根据下标访问子模块，仅当net是moduleList 或者 Sequential 实例时才可用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.0142, -0.0161]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for param in net.parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.MSELoss()    # nn built-in squared loss function\n",
    "                       # function prototype: `torch.nn.MSELoss(size_average=None, reduce=None, reduction='mean')`\n",
    "# 均方误差"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "优化函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    lr: 0.03\n",
      "    momentum: 0\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# torch.optim模块提供了很多常用的优化算法比如SGD、Adam和RMSProp等\n",
    "#下面我们创建一个用于优化net所有参数的优化器实例，并指定学习率为0.03的小批量随机梯度下降（SGD）为优化算法。\n",
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.03)   # built-in random gradient descent function\n",
    "print(optimizer)  # function prototype: `torch.optim.SGD(params, lr=, momentum=0, dampening=0, weight_decay=0, nesterov=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss: 0.000201\n",
      "epoch 2, loss: 0.000067\n",
      "epoch 3, loss: 0.000060\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 3\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    for X, y in data_iter:\n",
    "        output = net(X)\n",
    "        l = loss(output, y.view(-1, 1))  # 等价于  上面l = loss(net(X, w, b), y).sum() \n",
    "        optimizer.zero_grad() # reset gradient, equal to net.zero_grad()\n",
    "        l.backward()\n",
    "        optimizer.step()\n",
    "    print('epoch %d, loss: %f' % (epoch, l.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, -3.4] tensor([[ 2.0003, -3.3989]])\n",
      "4.2 tensor([4.2006])\n"
     ]
    }
   ],
   "source": [
    "dense = net[0] #取参\n",
    "print(true_w, dense.weight.data)\n",
    "print(true_b, dense.bias.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
